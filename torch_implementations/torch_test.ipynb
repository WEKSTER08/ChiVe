{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Before masking': Parameter containing:\n",
      "tensor([[ 0.1795, -0.2665, -0.5580,  0.8341,  0.1870,  0.2783],\n",
      "        [ 2.0395, -0.0427,  0.6600, -1.0849, -0.0823, -1.1895],\n",
      "        [ 1.3630,  1.1436,  0.8650,  0.6246, -0.2393,  0.4165],\n",
      "        [-0.1855,  1.3889,  0.1607,  1.2954,  1.1938,  0.2196],\n",
      "        [ 0.4168, -0.1767,  0.4800, -0.3006,  0.9134, -1.0233],\n",
      "        [-0.3070, -0.3941, -1.1438,  0.5393, -1.4720,  0.2769]],\n",
      "       requires_grad=True)}\n",
      "tensor([[ 0.1795, -0.2665, -0.5580,  0.8341,  0.1870,  0.2783],\n",
      "        [ 2.0395, -0.0427,  0.6600, -1.0849, -0.0823, -1.1895],\n",
      "        [ 1.3630,  1.1436,  0.8650,  0.6246, -0.2393,  0.4165],\n",
      "        [-0.1855,  1.3889,  0.1607,  1.2954,  1.1938,  0.2196],\n",
      "        [ 0.4168, -0.1767,  0.4800, -0.3006,  0.9134, -1.0233],\n",
      "        [-0.3070, -0.3941, -1.1438,  0.5393, -1.4720,  0.2769]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.1795, -0.0000, -0.5580,  0.8341,  0.1870,  0.0000],\n",
      "        [ 2.0395, -0.0000,  0.6600, -1.0849, -0.0823, -0.0000],\n",
      "        [ 1.3630,  0.0000,  0.8650,  0.6246, -0.2393,  0.0000],\n",
      "        [-0.1855,  0.0000,  0.1607,  1.2954,  1.1938,  0.0000],\n",
      "        [ 0.4168, -0.0000,  0.4800, -0.3006,  0.9134, -0.0000],\n",
      "        [-0.3070, -0.0000, -1.1438,  0.5393, -1.4720,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.1795, -0.0000, -0.5580,  0.0000,  0.1870,  0.0000],\n",
      "        [ 2.0395, -0.0000,  0.6600, -0.0000, -0.0823, -0.0000],\n",
      "        [ 1.3630,  0.0000,  0.8650,  0.0000, -0.2393,  0.0000],\n",
      "        [-0.1855,  0.0000,  0.1607,  0.0000,  1.1938,  0.0000],\n",
      "        [ 0.4168, -0.0000,  0.4800, -0.0000,  0.9134, -0.0000],\n",
      "        [-0.3070, -0.0000, -1.1438,  0.0000, -1.4720,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.1795, -0.0000, -0.5580,  0.0000,  0.1870,  0.2783],\n",
      "        [ 2.0395, -0.0000,  0.6600, -0.0000, -0.0823, -1.1895],\n",
      "        [ 1.3630,  0.0000,  0.8650,  0.0000, -0.2393,  0.4165],\n",
      "        [-0.1855,  0.0000,  0.1607,  0.0000,  1.1938,  0.2196],\n",
      "        [ 0.4168, -0.0000,  0.4800, -0.0000,  0.9134, -1.0233],\n",
      "        [-0.3070, -0.0000, -1.1438,  0.0000, -1.4720,  0.2769]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## testing weight matrix\n",
    "hidden_size =6\n",
    "W = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "timesteps = [1,2,3,4]\n",
    "clockrates = [1,3,2,5]\n",
    "def masking_function(hidden_size,clock_val):\n",
    "    mask = []\n",
    "    for i in range(hidden_size):\n",
    "        if i%2==0 or i%clock_val == 0:\n",
    "            mask.append(1) \n",
    "        else : mask.append(0)\n",
    "\n",
    "    return torch.FloatTensor(mask)\n",
    "\n",
    "\n",
    "pp.pprint({\"Before masking\": W})\n",
    "for i,timestep in enumerate(timesteps):\n",
    "    mask = masking_function(hidden_size,clockrates[i])\n",
    "    pp.pprint(W*mask)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import pprint as pp\n",
    "def masking_function(hidden_size,clock_val):\n",
    "    mask = []\n",
    "    for i in range(hidden_size):\n",
    "        if i%2==0 or i%clock_val == 0:\n",
    "            mask.append(1) \n",
    "        else : mask.append(0)\n",
    "\n",
    "    return torch.FloatTensor(mask)\n",
    "\n",
    "mask = masking_function(12,2)\n",
    "print(mask[0].dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000e+00, -8.7423e-08])\n",
      "tensor([4.0739, 3.0899])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m pp\u001b[39m.\u001b[39mpprint(input_sequence)\n\u001b[1;32m      9\u001b[0m pp\u001b[39m.\u001b[39mpprint(clock_vals)\n\u001b[0;32m---> 10\u001b[0m input_sequence \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([input_sequence,clock_vals])\n\u001b[1;32m     11\u001b[0m input_sequence \u001b[39m=\u001b[39m input_sequence\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(input_sequence)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def generate_sinusoidal_data(num_points, freq=1, amplitude=1):\n",
    "    t = torch.arange(0, num_points, 1)\n",
    "    x = amplitude * torch.sin(2 * torch.pi * freq * t / num_points)\n",
    "    return x\n",
    "input_sequence = generate_sinusoidal_data(2)\n",
    "clock_vals = torch.tensor([random.uniform(1, 6) for _ in range(2)])\n",
    "pp.pprint(input_sequence)\n",
    "pp.pprint(clock_vals)\n",
    "input_sequence = torch.tensor([input_sequence,clock_vals])\n",
    "input_sequence = input_sequence.unsqueeze(1).unsqueeze(1)\n",
    "print(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def generate_non_repeating_subset(start, end, subset_size):\n",
    "    if subset_size > (end - start):\n",
    "        raise ValueError(\"Subset size cannot be greater than the range size.\")\n",
    "\n",
    "    numbers = list(range(start, end))\n",
    "    random.shuffle(numbers)\n",
    "    subset = numbers[:subset_size]\n",
    "    return subset\n",
    "\n",
    "import torch\n",
    "\n",
    "tst = torch.zeros(4)\n",
    "print(tst[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy of the torch chive architecture\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pack_sequence, unpack_sequence\n",
    "\n",
    "class CHIVE(nn.Module):\n",
    "    def __init__(self, latent_space_dim):\n",
    "        super(CHIVE, self).__init__()\n",
    "        self.latent_space_dim = latent_space_dim\n",
    "        self.encoder = None\n",
    "        self.model_input = None\n",
    "        self.frnn_shape = 3\n",
    "        self.phrnn_shape = 3\n",
    "        self.sylrnn_shape = 3\n",
    "        self.input_shape = [self.frnn_shape, self.phrnn_shape, self.sylrnn_shape]\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        self.frame_rate_rnn = nn.LSTM(input_size=self.frnn_shape, hidden_size=64, batch_first=True)\n",
    "        self.phone_rate_rnn= nn.LSTM(input_size=self.phrnn_shape, hidden_size=64, batch_first=True)\n",
    "        self.syllable_rate_rnn = nn.LSTM(input_size=self.sylrnn_shape, hidden_size=64, batch_first=True)\n",
    "        # # self.encoder_input = [self.frame_rate_rnn_input, self.phone_rate_rnn_input, self.syllable_rate_rnn_input]\n",
    "\n",
    "        # # frame_rate_rnn = self.add_rnn_layer(self.frame_rate_rnn_input, self.frnn_shape)\n",
    "        # # phone_rate_rnn = self.add_rnn_layer(self.phone_rate_rnn_input, self.phrnn_shape)\n",
    "\n",
    "        # merged_layer = torch.cat([self.frame_rate_rnn[:,-1,:],self.phone_rate_rnn_input, self.syllable_rate_rnn_input], dim=1)\n",
    "        # syllable_rate_rnn = self.add_rnn_layer(merged_layer.unsqueeze(1), self.sylrnn_shape)\n",
    "\n",
    "        # bottleneck = self._add_bottleneck(syllable_rate_rnn)\n",
    "\n",
    "        # self.model_input = self.encoder_input\n",
    "        # self.encoder = nn.ModuleList([self.frame_rate_rnn_input, self.phone_rate_rnn_input, self.syllable_rate_rnn_input, bottleneck])\n",
    "        pass\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.encoder)\n",
    "\n",
    "    def compile(self, learning_rate=0.0001):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train(self, x_train, y_train, batch_size, num_epochs):\n",
    "        frnn_train, phrnn_train, sylrnn_train = x_train\n",
    "        frnn_train = torch.tensor(frnn_train, dtype=torch.float32)\n",
    "        phrnn_train = torch.tensor(phrnn_train, dtype=torch.float32)\n",
    "        sylrnn_train = torch.tensor(sylrnn_train, dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "        dataset = torch.utils.data.TensorDataset(frnn_train, phrnn_train, sylrnn_train, y_train)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for data in train_loader:\n",
    "                frnn_batch, phrnn_batch, sylrnn_batch, y_batch = data\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.forward([frnn_batch, phrnn_batch, sylrnn_batch])\n",
    "                loss = self.loss_function(output, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.frame_rate_rnn, self.phone_rate_rnn, self.syllable_rate_rnn = x\n",
    "        merged_layer = torch.cat([self.frame_rate_rnn[:, -1, :], self.phone_rate_rnn[:, -1, :], self.syllable_rate_rnn[:, -1, :]], dim=1)\n",
    "        return self._add_bottleneck(merged_layer.unsqueeze(1))\n",
    "\n",
    "    def _add_bottleneck(self, x):\n",
    "        lstm_units = 1\n",
    "        x, _ = nn.LSTM(input_size=x.size(-1), hidden_size=lstm_units, batch_first=True)(x)\n",
    "        return x[:, -1, :]\n",
    "\n",
    "    def add_rnn_layer(self, layer_input, shape):\n",
    "        lstm_units = 64\n",
    "        x, _ = nn.LSTM(input_size=shape, hidden_size=lstm_units,batch_first=True)(layer_input)\n",
    "        return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chive = CHIVE(latent_space_dim=1)\n",
    "    chive.summary()\n",
    "\n",
    "    num_samples = 1000\n",
    "    frnn_sequence_length = 2\n",
    "    phrnn_sequence_length = 3\n",
    "    sylrnn_sequence_length = 3\n",
    "\n",
    "    frnn_data = np.random.rand(num_samples, frnn_sequence_length, 2)\n",
    "    phrnn_data = np.random.rand(num_samples, phrnn_sequence_length, 3)\n",
    "    sylrnn_data = np.random.rand(num_samples, sylrnn_sequence_length, 3)\n",
    "    print(frnn_data)\n",
    "    chive.compile()\n",
    "\n",
    "    dummy_targets = np.random.rand(800, 1)\n",
    "    chive.train(x_train=[frnn_data, phrnn_data, sylrnn_data], y_train=dummy_targets, batch_size=16, num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "num_samples = 1\n",
    "\n",
    "test = torch.tensor(np.random.rand(num_samples,1, 13))\n",
    "print(test[0].dtype)\n",
    "\n",
    "# def generate_non_repeating_subset(start, end, subset_size):\n",
    "#     if subset_size > (end - start):\n",
    "#         raise ValueError(\"Subset size cannot be greater than the range size.\")\n",
    "\n",
    "#     print(start, end, subset_size)\n",
    "#     numbers = list(range(start, end))\n",
    "#     random.shuffle(numbers)\n",
    "#     print(numbers[:8])\n",
    "#     subset = numbers[:subset_size]\n",
    "#     return sorted(subset)\n",
    "\n",
    "# test = generate_non_repeating_subset(0,int(num_samples), int(num_samples/2-1))\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
