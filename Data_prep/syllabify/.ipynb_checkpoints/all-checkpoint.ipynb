{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "\n",
    "def stringify(syllables) :\n",
    "    '''This function takes a syllabification returned by syllabify and\n",
    "       turns it into a string, with phonemes spearated by spaces and\n",
    "       syllables spearated by periods.'''\n",
    "    ret = []\n",
    "    for syl in syllables :\n",
    "        stress, onset, nucleus, coda = syl\n",
    "        if stress != None and len(nucleus) != 0 :\n",
    "            nucleus[0] += str(stress)\n",
    "        ret.append(\" \".join(onset + nucleus + coda))\n",
    "    return \" . \".join(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_words_mat(file_path, filename, save_directory):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data2 = file.read().replace('\\n', ' ')\n",
    "    data2 = data2.replace('\\t', ' ')\n",
    "\n",
    "    data2_arr = data2.split(' ')\n",
    "    while(\"\" in data2_arr):\n",
    "        data2_arr.remove(\"\")\n",
    "\n",
    "    words = []\n",
    "    start = []\n",
    "    end = []\n",
    "\n",
    "    for i in range(0, len(data2_arr), 5):\n",
    "        start.append(data2_arr[i+2])\n",
    "        if i+2+5 < len(data2_arr) and float(data2_arr[i+2]) + float(data2_arr[i+3]) > float(data2_arr[i+2+5]):\n",
    "            end.append(str(float(data2_arr[i+2+5])))\n",
    "        else:\n",
    "            end.append(str(float(data2_arr[i+2]) + float(data2_arr[i+3])))\n",
    "        words.append(data2_arr[i+4])\n",
    "        # print(start[-1], end[-1], words[-1])\n",
    "\n",
    "    l1 = []\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        l1.append([start[i], end[i]])\n",
    "    mdic = {\"spurtWordTimes\": np.array(l1, dtype=np.float_), \"words\": words}\n",
    "    # savemat(f\"{filename[:-4]}_words.mat\", mdic)\n",
    "    savemat(f\"{save_directory}words/{filename[:-4]}_words.mat\", mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spn_containing_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (syllabifier.py, line 69)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home2/zishan.kazi/research/syllabify/python/syllabify/syllabifier.py\"\u001b[0;36m, line \u001b[0;32m69\u001b[0m\n\u001b[0;31m    raise ValueError, \"File must start with a section header such as [consonants].\"\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from python.syllabify import syllabifier\n",
    "language = syllabifier.English # or: syllabifier.loadLanguage(\"english.cfg\")\n",
    "\n",
    "def save_vowel_and_syllable_mat(file_path, filename, save_directory):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read().replace('\\n', ' ')\n",
    "    data = data.replace('\\t', ' ')\n",
    "    data_arr = data.split(' ')\n",
    "    while(\"\" in data_arr):\n",
    "        data_arr.remove(\"\")\n",
    "    # print(data_arr)\n",
    "\n",
    "    final = ''\n",
    "    start = []\n",
    "    end = []\n",
    "    ph = []\n",
    "\n",
    "    for i in range(0, len(data_arr), 3):\n",
    "        if data_arr[i+2] == \"sil\":\n",
    "            continue\n",
    "        if data_arr[i+2] == \"spn\":\n",
    "            spn_containing_files.append(filename)\n",
    "            print(filename)\n",
    "            return\n",
    "        start.append(data_arr[i])\n",
    "        end.append(data_arr[i+1])\n",
    "        ph.append(data_arr[i+2])  \n",
    "        final += data_arr[i+2].upper() + ' '\n",
    "\n",
    "    syllables = syllabifier.syllabify(language, final)\n",
    "\n",
    "    main_str = stringify(syllables)\n",
    "    arr = main_str.split(\".\")   # syllable array\n",
    "\n",
    "    final_st = []   # start time of syllable\n",
    "    final_end = []  # end time of syllable\n",
    "    syl = []\n",
    "\n",
    "    c = 0\n",
    "    for e in arr:\n",
    "        phoneme = e.split(\" \")\n",
    "        while(\"\" in phoneme):\n",
    "            phoneme.remove(\"\")\n",
    "        \n",
    "        final_st.append(start[c])\n",
    "        final_end.append(end[c+len(phoneme)-1])\n",
    "        syl.append(phoneme)\n",
    "        c += len(phoneme)\n",
    "\n",
    "    # Vowel\n",
    "    v = syllabifier.English[\"vowels\"]\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    for i in range(len(ph)):\n",
    "        s = ph[i]\n",
    "        if len(ph[i]) == 3:\n",
    "            s = ph[i][:-1]\n",
    "        if s.upper() in v:\n",
    "            l1.append(float(start[i]))\n",
    "            l2.append(float(end[i]))\n",
    "\n",
    "    mdic = {\"vowelStartTime\": np.array(l1, dtype=np.float32), \"vowelEndTime\": np.array(l2, dtype=np.float32)}\n",
    "    savemat(f\"{save_directory}vowel/{filename[:-4]}_vowel.mat\", mdic)\n",
    "    # savemat(f\"{save_directory}{filename[:-4]}_vowel.mat\", mdic)\n",
    "\n",
    "    # Syllable\n",
    "    st = []\n",
    "    for s in syl:\n",
    "        ss = \"\"\n",
    "        for ph in s:\n",
    "            temp = ph.lower()\n",
    "            if len(temp) == 3:\n",
    "                temp = temp[:-1]\n",
    "            ss += temp + \" \"\n",
    "        if len(ss):\n",
    "            ss = ss[:-1]\n",
    "            st.append(ss)\n",
    "\n",
    "    st2 = []\n",
    "    for i in range(len(final_st)):\n",
    "        st2.append([final_st[i], final_end[i]])\n",
    "\n",
    "    mdic = {\"spurtSyl\": np.array(st), \"spurtSylTimes\": np.array(st2, dtype=np.float_)}\n",
    "    savemat(f\"{save_directory}syllable/{filename[:-4]}_syllable.mat\", mdic)\n",
    "    # savemat(f\"{save_directory}{filename[:-4]}_syllable.mat\", mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save_vowel_and_syllable_mat(\"S2352179115300041_26.txt\", \"S2352179115300041_26.txt\", \"./\")\n",
    "vowel_syl_directory = \"../FA_result_2604/FA_result/\"\n",
    "filename = \"S2352179115300041_26.txt\"\n",
    "save_vowel_and_syllable_mat(f'{vowel_syl_directory}{filename}', \"pablo.txt\", \"./\")\n",
    "spn_containing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0079642514000887_18.txt\n",
      "S2212671612000741_17.txt\n",
      "S0370269304007634_3.txt\n",
      "S221267161200220X_10.txt\n",
      "S0031920113000708_0.txt\n",
      "S221267161200220X_3.txt\n",
      "S0305054816300867_18.txt\n",
      "S0003491615001955_6.txt\n",
      "S0021999115007238_2.txt\n",
      "S0032386107010518_24.txt\n",
      "S0370269304007634_10.txt\n",
      "S037596011300741X_18.txt\n",
      "S0370157312000105_3.txt\n",
      "S0370269304007439_13.txt\n",
      "S0370269304009803_7.txt\n",
      "S221267161200176X_7.txt\n",
      "S074756321630348X_7.txt\n",
      "S0375960113010839_19.txt\n",
      "S0021999113005603_14.txt\n",
      "S0098300413002124_5.txt\n",
      "S0021999113005603_20.txt\n",
      "S0370269304009074_0.txt\n",
      "S1364815216303541_9.txt\n",
      "S0022311515301963_5.txt\n",
      "S0032386109006612_12.txt\n",
      "S0167273813005298_2.txt\n",
      "S0098300413002124_23.txt\n",
      "S1364815216303541_4.txt\n",
      "S0168365913003295_11.txt\n",
      "S221267161200176X_1.txt\n",
      "S2212667814001208_7.txt\n",
      "S2212667812000895_4.txt\n",
      "S0370269304007634_2.txt\n",
      "S0997754612001318_13.txt\n",
      "S0098300414000259_10.txt\n",
      "S0375960115004120_11.txt\n",
      "S0375960112002885_9.txt\n",
      "S0032386109006612_15.txt\n",
      "S0021999113005603_15.txt\n",
      "S0167273812003025_0.txt\n",
      "S0305054816300867_3.txt\n",
      "S2212671612000741_7.txt\n",
      "S2212667814001440_11.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# all these should end with a slash\n",
    "word_directory = \"../FA_result_2604/FA_result/\"\n",
    "vowel_syl_directory = \"../FA_result_phn_level_2704/\"\n",
    "save_directory = \"../mat_files_new/\"\n",
    "\n",
    "# blacklist = [\"S2212667814000380\", \"S0885230816301759\", \"S2214657115000179\", \"S0377025714000317\"]\n",
    "blacklist = []\n",
    "\n",
    "for filename in os.listdir(word_directory):\n",
    "    if filename[:17] not in blacklist and filename.endswith(\".txt\"):\n",
    "        save_words_mat(f'{word_directory}{filename}', filename, save_directory)\n",
    "\n",
    "for filename in os.listdir(vowel_syl_directory):\n",
    "    if filename[:17] not in blacklist and filename.endswith(\".txt\"):\n",
    "        save_vowel_and_syllable_mat(f'{vowel_syl_directory}{filename}', filename, save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [[0.   0.1 ]\n",
      " [0.1  0.77]\n",
      " [0.77 0.98]\n",
      " [0.98 1.44]\n",
      " [1.44 2.16]\n",
      " [2.38 2.66]\n",
      " [2.66 3.31]\n",
      " [3.31 3.44]\n",
      " [3.44 3.58]\n",
      " [3.58 4.34]]\n",
      "10 ['to         ' 'differences' 'in         ' 'surface    ' 'area       '\n",
      " 'rougher    ' 'samples    ' 'would      ' 'be         ' 'expected   ']\n"
     ]
    }
   ],
   "source": [
    "mat = scipy.io.loadmat(f\"/home/zk/IIIT-H/research/TTS/mat_files_new/words/S0010938X15002085_17_words.mat\")\n",
    "print(len(mat[\"spurtWordTimes\"]), mat[\"spurtWordTimes\"])\n",
    "print(len(mat[\"words\"]), mat[\"words\"])\n",
    "# print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 ['ay    ' 's ey  ' 'd ah  ' 's n ow' 'n aa t' 't uw  ' 'm aa  ' 'r ow  ']\n",
      "8 [[0.11       0.19      ]\n",
      " [0.19       0.46000001]\n",
      " [0.46000001 0.55000001]\n",
      " [0.55000001 1.07000005]\n",
      " [1.10000002 1.27999997]\n",
      " [1.27999997 1.38      ]\n",
      " [1.38       1.57000005]\n",
      " [1.57000005 1.88999999]]\n"
     ]
    }
   ],
   "source": [
    "mat = scipy.io.loadmat(f\"/home/zk/IIIT-H/research/TTS/TCSSBC/syllable.mat\")\n",
    "print(len(mat[\"spurtSyl\"]), mat[\"spurtSyl\"])\n",
    "print(len(mat[\"spurtSylTimes\"]), mat[\"spurtSylTimes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove spn containing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_file_prefix = []\n",
    "for file in spn_containing_files:\n",
    "    remove_file_prefix.append(file.split(\"_\")[0])\n",
    "\n",
    "for filename in os.listdir(\"../mat_files_new/vowel/\"):\n",
    "    if filename[:17] in remove_file_prefix:\n",
    "        os.remove(f\"../mat_files_new/vowel/{filename}\")\n",
    "\n",
    "for filename in os.listdir(\"../mat_files_new/syllable/\"):\n",
    "    if filename[:17] in remove_file_prefix:\n",
    "        os.remove(f\"../mat_files_new/syllable/{filename}\")\n",
    "\n",
    "for filename in os.listdir(\"../mat_files_new/words/\"):\n",
    "    if filename[:17] in remove_file_prefix:\n",
    "        os.remove(f\"../mat_files_new/words/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5449\n",
      "5449\n",
      "5449\n"
     ]
    }
   ],
   "source": [
    "! ls ../mat_files_new/vowel | wc -l\n",
    "! ls ../mat_files_new/syllable | wc -l\n",
    "! ls ../mat_files_new/words | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doubts\n",
    "- <s>words.mat has `words` dtype as `<U9` whereas yours is `<U8`. </s>\n",
    "- `<unk>` is also included in words.mat.\n",
    "- How do we handle spn and sil?\n",
    "    - Instead of spn can we insert the word from the txt file which we have?\n",
    "    - 2921/6076 files have spn\n",
    "- Remove the files on which the transcription is changed and also where the phoneme conversion failed (check mail)\n",
    "- <s><strong>Correct the endtime which is the addition of start time and end time.</strong></s>\n",
    "- Start and end time, till what decimal place should we consider?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
